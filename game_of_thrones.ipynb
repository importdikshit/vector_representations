{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All the native dependencies. \n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import glob\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All the non native dependencies.\n",
    "\n",
    "import nltk \n",
    "import gensim.models.word2vec as word\n",
    "import numpy as np\n",
    "import sklearn.manifold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL THE SETUP HAS BEEN DONE! SOME PRELIMINARY DATA CLEANING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "book_names = os.listdir('./game_of_thrones/')\n",
    "book_names = sorted(glob.glob('./game_of_thrones/*.txt'))\n",
    "## Apparently, glob does proper filename expansion. Therefore glob > os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./game_of_thrones/got1.txt',\n",
       " './game_of_thrones/got2.txt',\n",
       " './game_of_thrones/got3.txt',\n",
       " './game_of_thrones/got4.txt',\n",
       " './game_of_thrones/got5.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for book_name in book_names:\n",
    "#     this_one = open(book_name)\n",
    "#     this_one.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COME BACK AND DO MORE EXTENSIVE DATA CLEANING TO SEE IF IT CHANGES RESULTS.\n",
    "\n",
    "### https://people.duke.edu/~ccc14/sta-663/TextProcessingExtras.html\n",
    "### https://www.analyticsvidhya.com/blog/2014/11/text-data-cleaning-steps-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting all books to UTF8 and putting them into the same string. \n",
    "# Interesting article on encodings - if you every need it again. \n",
    "# http://kunststube.net/encoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus is 1770659 characters long\n",
      "Corpus is 4071041 characters long\n",
      "Corpus is 6391405 characters long\n",
      "Corpus is 8107945 characters long\n",
      "Corpus is 9719485 characters long\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for this_book in book_names:\n",
    "    with codecs.open(this_book, \"r\", \"utf-8\") as book:\n",
    "        corpus_raw += book.read()\n",
    "    print(\"Corpus is {0} characters long\".format(len(corpus_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT TRY AND CALL THE CORPUS TO VIEW ITS CONTENTS. \n",
    "# Learnt this the hard way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This edition contains the complete text of the original hardcover edition.\\n\\nNOT ONE WORD HAS BEEN OMITTED.\\n\\nA CLASH OF KINGS\\n\\nA Bantam Spectra Book\\n\\nPUBLISHING HISTORY\\n\\nBantam Spectra hardcover edition published February 1999\\n\\nBantam Spectra paperback edition / September 2000\\n\\nSPECTRA and the portrayal of a boxed “s” are trademarks of Bantam Books, a division of Random House, Inc.\\n\\nAll rights reserved.\\n\\nCopyright © 1999 by George R. R. Martin.\\n\\nMaps by James Sinclair.\\n\\nHeraldic crest by Virginia Norey.\\n\\nLibrary of Congress Catalog Card Number: 98-37954.\\n\\nNo part of this book may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or by any information storage and retrieval system, without permission in writing from the publisher.\\n\\nVisit our website at www.bantamdell.com\\n\\nBantam Books, the rooster colophon, Spectra and the portrayal of a boxed “s” are registered trademarks of Random House Inc.\\n\\neISBN: 978-0-553-89785-2\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_raw[:1000]\n",
    "# ALL OF THIS JUNK NEEDS TO DISAPPEAR IN THE SECOND PASS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', 'was', 'here', 'the', 'ravens', 'came', 'after', 'long', 'flight']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sentences[10]\n",
    "\n",
    "# Split these tokenized sentences, down to tokenized words\n",
    "\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    words = clean.split()\n",
    "    return words\n",
    "\n",
    "raw_example = sentence_to_wordlist(raw_sentences[10])\n",
    "raw_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heraldic crest by Virginia Norey.\n",
      "['Heraldic', 'crest', 'by', 'Virginia', 'Norey']\n"
     ]
    }
   ],
   "source": [
    "print(raw_sentences[5])\n",
    "print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 1,818,103 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I DO NOT KNOW WHY WE ARENT JUST SIMPLY TAKING THE WORDS AND CONCATENATING THEM. THERE SEEMS TO BE SOME REASON TO PRESERVE THE SENTENCE LEVEL INTEGRITY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS!\n",
    "\n",
    "num_features = 300\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thrones = word.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thrones.build_vocab(sentences)\n",
    "\n",
    "# Main Step - starts training on the given corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-13 23:05:25,406 : INFO : training model with 4 workers on 17277 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=7\n",
      "2017-06-13 23:05:26,496 : INFO : PROGRESS: at 1.97% examples, 134782 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:27,511 : INFO : PROGRESS: at 4.41% examples, 150675 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:28,522 : INFO : PROGRESS: at 6.95% examples, 156604 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:29,560 : INFO : PROGRESS: at 9.54% examples, 160191 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:30,568 : INFO : PROGRESS: at 12.01% examples, 163473 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:31,569 : INFO : PROGRESS: at 14.42% examples, 164392 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:32,647 : INFO : PROGRESS: at 17.26% examples, 166558 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:33,671 : INFO : PROGRESS: at 19.80% examples, 169152 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:34,673 : INFO : PROGRESS: at 22.52% examples, 171656 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-13 23:05:35,751 : INFO : PROGRESS: at 25.07% examples, 170921 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:36,771 : INFO : PROGRESS: at 28.03% examples, 172605 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:37,883 : INFO : PROGRESS: at 30.38% examples, 170827 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:38,886 : INFO : PROGRESS: at 32.44% examples, 169028 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:39,991 : INFO : PROGRESS: at 34.65% examples, 166727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:40,994 : INFO : PROGRESS: at 37.04% examples, 166376 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:42,006 : INFO : PROGRESS: at 38.68% examples, 163609 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-13 23:05:43,016 : INFO : PROGRESS: at 40.52% examples, 162090 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:44,030 : INFO : PROGRESS: at 42.98% examples, 162394 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:45,093 : INFO : PROGRESS: at 45.50% examples, 162634 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:46,141 : INFO : PROGRESS: at 48.39% examples, 163368 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:47,150 : INFO : PROGRESS: at 50.78% examples, 163925 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:48,158 : INFO : PROGRESS: at 53.22% examples, 164494 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:49,163 : INFO : PROGRESS: at 55.89% examples, 164968 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:50,307 : INFO : PROGRESS: at 58.36% examples, 164486 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-13 23:05:51,403 : INFO : PROGRESS: at 60.51% examples, 163763 words/s, in_qsize 6, out_qsize 1\n",
      "2017-06-13 23:05:52,579 : INFO : PROGRESS: at 62.73% examples, 162351 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:53,686 : INFO : PROGRESS: at 64.50% examples, 160353 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-13 23:05:54,705 : INFO : PROGRESS: at 66.20% examples, 158735 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:55,707 : INFO : PROGRESS: at 68.37% examples, 158072 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:56,753 : INFO : PROGRESS: at 70.77% examples, 158462 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:57,803 : INFO : PROGRESS: at 73.31% examples, 159059 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:58,830 : INFO : PROGRESS: at 76.27% examples, 159931 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:05:59,866 : INFO : PROGRESS: at 78.75% examples, 160466 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:00,876 : INFO : PROGRESS: at 81.16% examples, 160881 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:01,880 : INFO : PROGRESS: at 83.62% examples, 161105 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:02,907 : INFO : PROGRESS: at 86.21% examples, 161441 words/s, in_qsize 8, out_qsize 1\n",
      "2017-06-13 23:06:03,950 : INFO : PROGRESS: at 88.37% examples, 160677 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:04,992 : INFO : PROGRESS: at 90.46% examples, 160349 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:06,006 : INFO : PROGRESS: at 92.30% examples, 159592 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:07,036 : INFO : PROGRESS: at 94.26% examples, 158966 words/s, in_qsize 8, out_qsize 1\n",
      "2017-06-13 23:06:08,060 : INFO : PROGRESS: at 96.52% examples, 158591 words/s, in_qsize 8, out_qsize 0\n",
      "2017-06-13 23:06:09,151 : INFO : PROGRESS: at 98.56% examples, 158139 words/s, in_qsize 7, out_qsize 0\n",
      "2017-06-13 23:06:09,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-06-13 23:06:09,728 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-06-13 23:06:09,731 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-06-13 23:06:09,750 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-06-13 23:06:09,752 : INFO : training on 9090515 raw words (7019467 effective words) took 44.3s, 158497 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7019467"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thrones.train(sentences, total_examples= thrones.corpus_count, epochs= thrones.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-13 23:07:42,043 : INFO : saving Word2Vec object under ./trained_models/thrones.w2v, separately None\n",
      "2017-06-13 23:07:42,047 : INFO : not storing attribute syn0norm\n",
      "2017-06-13 23:07:42,048 : INFO : not storing attribute cum_table\n",
      "2017-06-13 23:07:43,616 : INFO : saved ./trained_models/thrones.w2v\n"
     ]
    }
   ],
   "source": [
    "thrones.save(os.path.join(\"./trained_models/\", \"thrones.w2v\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DONE. TRAINED THIS MODEL - GAME OF THRONES. NOW, TRAINING HARRY POTTER. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
